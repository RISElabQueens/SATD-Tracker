{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Step 0: Clone the repository"
      ],
      "metadata": {
        "id": "573jXiI85SHA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "55nNFtAVxFhE"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WDobDBtN0BEB"
      },
      "outputs": [],
      "source": [
        "#%rm -r 'projects'\n",
        "!mkdir 'projects'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "re9X9i-n0o99"
      },
      "outputs": [],
      "source": [
        "%cd 'projects'\n",
        "!git clone https://github.com/apache/commons-math.git\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1-A: Extract the sequence of commits in the master branch"
      ],
      "metadata": {
        "id": "hWuZIfsT5Zvy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0tNhKg1ANUs"
      },
      "outputs": [],
      "source": [
        "!pip install GitPython"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "thsdcwliADQl"
      },
      "outputs": [],
      "source": [
        "# Extract the sequence of commits in the master branch\n",
        "from git import Repo\n",
        "\n",
        "# Get the repository\n",
        "repo = Repo(\"projects/commons-math\")\n",
        "\n",
        "# Get the master branch\n",
        "master_branch = repo.head.reference\n",
        "\n",
        "# Get all master commits\n",
        "master_commits_raw = list(repo.iter_commits(master_branch))\n",
        "\n",
        "# sort the commits by date\n",
        "master_commits_raw = sorted(master_commits_raw, key=lambda x: x.committed_datetime)\n",
        "\n",
        "# remove master commits that are not the first parent\n",
        "master_commits = [master_commits_raw[-1]]\n",
        "while len(master_commits[-1].parents)>0:\n",
        "    master_commits.append(master_commits[-1].parents[0])\n",
        "master_commits.reverse()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8MSyFDHCMb5",
        "outputId": "c8f56316-1b5a-4479-ef18-a938af9183aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first commit in the master branch: 2003-05-12 15:07:54+00:00 4a8cbc286781f1ecff6b8e0f8e20e30eb9f5a709\n",
            "The last commit in the master branch: 2023-05-09 00:31:44+01:00 cf78d0b2c6e74f5197945394f978f07af09ecd45\n",
            "Total number of commits in the master branch: 6617\n"
          ]
        }
      ],
      "source": [
        "# print the first and last commit:\n",
        "print(\"The first commit in the master branch:\", master_commits[0].committed_datetime, master_commits[0].hexsha)\n",
        "print(\"The last commit in the master branch:\", master_commits[-1].committed_datetime, master_commits[-1].hexsha)\n",
        "print(\"Total number of commits in the master branch:\", len(master_commits))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "wEiOukWUNJkA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f96311e-89ee-4e92-f919-d7e0043dc038"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of files in the last snapshot of the project: 1351\n"
          ]
        }
      ],
      "source": [
        "# get all files exist in the last commit, you can use it later if you want to extract SATDs from a specific file\n",
        "last_commit = master_commits[-1]\n",
        "files = [item.path for item in last_commit.tree.traverse() if item.type == \"blob\"]\n",
        "print(\"Number of files in the last snapshot of the project:\", len(files))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1-B: Extract the sequence of hunks for all files"
      ],
      "metadata": {
        "id": "QsnYLf-h4B5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8z8p8qWjx3hT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8de623d-62af-47ee-80aa-e0be640e4992"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidiff\n",
            "  Downloading unidiff-0.7.5-py2.py3-none-any.whl (14 kB)\n",
            "Installing collected packages: unidiff\n",
            "Successfully installed unidiff-0.7.5\n"
          ]
        }
      ],
      "source": [
        "!pip install unidiff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "paUkSryY_Y7t"
      },
      "outputs": [],
      "source": [
        "from io import StringIO\n",
        "from unidiff import PatchSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "s_TTr8NV3jRt"
      },
      "outputs": [],
      "source": [
        "def get_files_hunks_for_a_commit(repo , commit, file=None):\n",
        "    EMPTY_TREE_SHA = '4b825dc642cb6eb9a060e54bf8d69288fbee4904'\n",
        "    if len(commit.parents)==0:\n",
        "        parent = EMPTY_TREE_SHA\n",
        "    else:\n",
        "        parent = commit.parents[0] # ??? is parents[0] always the parent in the master branch\n",
        "    if file is None:\n",
        "        uni_diff_text = repo.git.diff(parent, commit)\n",
        "    else:\n",
        "        uni_diff_text = repo.git.diff(parent, commit, file)\n",
        "    patch_set = PatchSet(StringIO(uni_diff_text)) # we have to use PatchSet library because diff in gitpython provides all information in string (even with parent.diff(commit), the diff for each file/hunk is string)\n",
        "    file_patchindex = {} # the index of files in patch_set\n",
        "    for patched_file in patch_set:\n",
        "        file_patchindex[patched_file.path] = len(file_patchindex)\n",
        "\n",
        "    files_hunks = {}\n",
        "    oldpath_newpath = {}    # we need the file name in the time (commit) that the SATD action is occured \n",
        "    if parent==EMPTY_TREE_SHA:\n",
        "        if file is None:\n",
        "            diff = commit.diff(EMPTY_TREE_SHA, create_patch=True) # we have to use this method because PatchSet doesn't provide the file renames correctly\n",
        "        else:\n",
        "            diff = commit.diff(EMPTY_TREE_SHA, file, create_patch=True) # we have to use this method because PatchSet doesn't provide the file renames correctly\n",
        "    else:\n",
        "        if file is None:\n",
        "            diff = parent.diff(commit) # we have to use this method because PatchSet doesn't provide the file renames correctly\n",
        "        else:\n",
        "            diff = parent.diff(commit, file) # we have to use this method because PatchSet doesn't provide the file renames correctly\n",
        "\n",
        "    for patch in diff:\n",
        "        if patch.b_path in file_patchindex:\n",
        "            indx = file_patchindex[patch.b_path]\n",
        "            hunks = patch_set[indx]\n",
        "        elif patch.a_path in file_patchindex:\n",
        "            indx = file_patchindex[patch.a_path]\n",
        "            hunks = patch_set[indx]\n",
        "        else:\n",
        "            print('Nither patch.b_path nor patch.a_path found in file_patchindex:')\n",
        "            print('a_path:',patch.a_path)\n",
        "            print('b_path:',patch.b_path)\n",
        "            hunks = []\n",
        "\n",
        "        files_hunks[patch.b_path] = hunks\n",
        "        if patch.change_type in ['R']: # C: copy   R:rename  include C??????\n",
        "            oldpath_newpath[patch.rename_from] = patch.b_path\n",
        "\n",
        "    return oldpath_newpath, files_hunks\n",
        "\n",
        "\n",
        "def get_files_hunks_for_all_commits(repo, commits, file=None):\n",
        "    files_hunks = {}\n",
        "    i=0\n",
        "    for commit in commits:\n",
        "        if i%100 == 0:\n",
        "            print('Processed commits:',i) \n",
        "        oldpath_newpath, fh = get_files_hunks_for_a_commit(repo, commit, file=file)\n",
        "        # update the keys in files_hunks according to oldpath_newpath\n",
        "        for oldp,newp in oldpath_newpath.items():\n",
        "            # if newp already exists in files_hunks (meaning that there was a file with the same name but deleted before this commit), we convert its key to filepath_#_deletionCommit\n",
        "            if newp in files_hunks:\n",
        "                #print('newp already exists in files_hunks ===>',newp)\n",
        "                hexsha = files_hunks[newp][-1]['commit'].hexsha\n",
        "                files_hunks[newp+'_#_'+hexsha] = files_hunks.pop(newp)\n",
        "                #print('we change that key to:',newp+'_#_'+hexsha)\n",
        "            if oldp in files_hunks:\n",
        "                files_hunks[newp] = files_hunks.pop(oldp)\n",
        "            #else:\n",
        "                #print(\"oldpath not found in files_hunks:\",oldp)\n",
        "        # add the new fh to files_hunks\n",
        "        for f,h in fh.items():\n",
        "            if f not in files_hunks:\n",
        "                files_hunks[f] = []\n",
        "            files_hunks[f].append({'commit':commit, 'file':f, 'hunks':h})\n",
        "        i += 1\n",
        "    return files_hunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvO969rnDbSo"
      },
      "outputs": [],
      "source": [
        "files_hunks = get_files_hunks_for_all_commits(repo, master_commits) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzYIBax0XGOx",
        "outputId": "c3a56a8d-27c8-49e2-a892-6dafa018fff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total files we extracted their hunks: 4771\n"
          ]
        }
      ],
      "source": [
        "print(\"Total files we extracted their hunks:\", len(files_hunks))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Extract and track raw SATDs"
      ],
      "metadata": {
        "id": "rxX9z9Ui_BNX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Jwoom-HhnT_v"
      },
      "outputs": [],
      "source": [
        "# This code is based on MAT SATD detection introduced in paper \"How Far HaveWe Progressed in Identifying Self-admitted Technical Debts? A Comprehensive Empirical Study\"\n",
        "# https://github.com/Naplues/MAT/blob/master/src/main/methods/Mat.java\n",
        "def ismatch_MAT(string):\n",
        "    strings = string.split('//',1)\n",
        "    if len(strings)==2:\n",
        "        comment = strings[1]\n",
        "    else:\n",
        "        return False\n",
        "    comment = comment.lower().replace(\"'\",\"\")\n",
        "    tokens = comment.split(' ')\n",
        "    for token in tokens:\n",
        "        for keyword in ['todo','fixme','hack']:\n",
        "            if token.startswith(keyword) or token.endswith(keyword):\n",
        "                return True\n",
        "            if token=='xxx':\n",
        "                return True\n",
        "    return False\n",
        "\n",
        "# In this version we save more information about SATDs (i.e. hunk_index and SATD's context (its prev and next line))\n",
        "# This information will be used to detect the following SATD of each SATD (if exists)\n",
        "def get_raw_SATDs(hunks, steps):\n",
        "    newLineWarning = 'No newline at end of file' # this is a synthetic static warning that I should ignore, because it is not part of the user code\n",
        "    # an example for newLineWarning:\n",
        "        # file name: helix-core/src/test/java/org/apache/helix/alerts/TestEvaluateAlerts.java\n",
        "        # https://github.com/apache/helix/commit/f414aad4c9b26fc767eaf373f7691f8e0487a598  --> see deleted line 395\n",
        "    satds = []\n",
        "    if steps<=0:\n",
        "        steps = len(hunks)\n",
        "    for i in range(steps): # iterate commits\n",
        "        ####### detect deleted SATDs ########\n",
        "        for j in range(len(hunks[i]['hunks'])): # iterate hunks for deleted SATDs\n",
        "            hunk = hunks[i]['hunks'][j]\n",
        "            lines = str(hunk).split('\\n')[1:] # we ignore the first line because it is not part of the code (e.g. \"@@ -18,12 +18,8 @@\")\n",
        "            l = 0\n",
        "            for n in range(len(lines)):\n",
        "                prevLine = lines[n-1] if n>0 else ''\n",
        "                line = lines[n]\n",
        "                nextLine = lines[n+1] if n<len(lines)-1 else ''\n",
        "                if len(line)>0 and line[0]=='-':\n",
        "                    #if 'todo' in line.lower():\n",
        "                    if ismatch_MAT(line):\n",
        "                        codeLine = hunk.source_start + l\n",
        "                        for satd in satds:\n",
        "                            if satd['deleted_in_commit']==None and satd['line']==codeLine:\n",
        "                                if n!=0 and len(prevLine)>0 and prevLine[0]=='-':\n",
        "                                    satd['prev_line_content'] = prevLine[1:].strip()\n",
        "                                if n!=len(lines)-1 and len(nextLine)>0 and nextLine[0]=='-':\n",
        "                                    satd['next_line_content'] = nextLine[1:].strip()\n",
        "                                satd['deleted_in_commit']=hunks[i]['commit']\n",
        "                                satd['deleted_in_hunk']=j # hunk_index (in the old version that used vcsSHARK data, we used hunk_id, but now we use the hunk_index)\n",
        "                if len(line)==0 or (len(line)>0 and line[0]!='+'):\n",
        "                    l += 1\n",
        "        ####### update SATD line numbers ########\n",
        "        for satd in satds:\n",
        "            satd['line_change'] = 0\n",
        "        ## check hunks for deleted lines\n",
        "        for j in range(len(hunks[i]['hunks'])):\n",
        "            hunk = hunks[i]['hunks'][j]\n",
        "            for satd in satds:\n",
        "                if satd['deleted_in_commit']==None and satd['created_in_commit']!=hunks[i]['commit']: # probably no need the second condition but lets keep it just in case\n",
        "                    if satd['line']>=hunk.source_start:\n",
        "                        if satd['line']<hunk.source_start+hunk.source_length:\n",
        "                            satd['line_change'] -= satd['line']-hunk.source_start\n",
        "                        else:\n",
        "                            satd['line_change'] -= hunk.source_length\n",
        "        for satd in satds:\n",
        "            satd['line_before_update'] = satd['line'] # it will be used to sort satds in the next step \"check hunks for added lines\"\n",
        "            satd['line'] += satd['line_change']  # as the target_start is based on updated line numbers (after deletion) we have to first update line numbers here before checking for added lines\n",
        "        ## check hunks for added lines\n",
        "        for hunk in sorted(hunks[i]['hunks'], key=lambda item: item.target_start):\n",
        "            lines = str(hunk).split('\\n')[1:]\n",
        "            l = 0\n",
        "            unchanged_satds_l = []  # number of lines to be added to unchanged_satds (unchanged_satds are the satds that appear in the diff but their line doesn't start with - or +)\n",
        "            for line in lines:\n",
        "                #if len(line)>0 and line[0]!='-' and line[0]!='+' and 'todo' in line.lower():\n",
        "                if len(line)>0 and line[0]!='-' and line[0]!='+' and ismatch_MAT(line):\n",
        "                    unchanged_satds_l.append(l)\n",
        "                if len(line)==0 or (len(line)>0 and line[0]!='-' and line.strip()!=newLineWarning): \n",
        "                    l+=1\n",
        "            for satd in sorted(satds, key=lambda item: item['line_before_update']):\n",
        "                if satd['deleted_in_commit']==None and satd['created_in_commit']!=hunks[i]['commit']: # maybe no need the second condition but lets keep it just in case\n",
        "                    if satd['line']>=hunk.target_start:\n",
        "                        if satd['line']<hunk.target_start+hunk.target_length and len(unchanged_satds_l)>0:  # ?? it was hunk['new_start']+hunk['new_start'] but I think that was my mistake,\n",
        "                                                                                                            # so I updated it to hunk['new_start']+hunk['new_lines'], although the results remained unchange!\n",
        "                            satd['line'] += unchanged_satds_l[0]\n",
        "                            unchanged_satds_l = unchanged_satds_l[1:]\n",
        "                        else:\n",
        "                            satd['line'] += hunk.target_length\n",
        "        ####### find new SATDs ########\n",
        "        for j in range(len(hunks[i]['hunks'])): # iterate hunks for created SATDs\n",
        "            hunk = hunks[i]['hunks'][j]\n",
        "            lines = str(hunk).split('\\n')[1:]\n",
        "            l = 0\n",
        "            for n in range(len(lines)):\n",
        "                prevLine = lines[n-1] if n>0 else ''\n",
        "                line = lines[n]\n",
        "                nextLine = lines[n+1] if n<len(lines)-1 else ''\n",
        "                if len(line)>0 and line[0]=='+':\n",
        "                    #if 'todo' in re.findall(r\"[\\w']+|[.,!?;]\", line.lower()):\n",
        "                    if ismatch_MAT(line):\n",
        "                        codeLine = hunk.target_start + l\n",
        "                        satd = {'created_in_file':hunks[i]['file'], 'created_in_line':codeLine, 'line':codeLine, 'created_in_commit':hunks[i]['commit'], 'deleted_in_commit':None, 'created_in_hunk':j, 'deleted_in_hunk':None, 'content':line[1:].strip()}\n",
        "                        if n!=0 and len(prevLine)>0 and prevLine[0]=='+':\n",
        "                            satd['prev_line_content'] = prevLine[1:].strip()\n",
        "                        else:\n",
        "                            satd['prev_line_content'] = ''\n",
        "                        if n!=len(lines)-1 and len(nextLine)>0 and nextLine[0]=='+':\n",
        "                            satd['next_line_content'] = nextLine[1:].strip()    \n",
        "                        else:\n",
        "                            satd['next_line_content'] = ''\n",
        "                        satds.append(satd)\n",
        "                if len(line)==0 or (len(line)>0 and line[0]!='-' and line.strip()!=newLineWarning):\n",
        "                    l += 1\n",
        "    for satd in satds:\n",
        "        if 'line_change' in satd:\n",
        "            del satd['line_change']\n",
        "        if 'line_before_update' in satd:\n",
        "            del satd['line_before_update']\n",
        "    return satds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7thKbFCk-ugS"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "# if target_commit=None: Extract all satds in the master branch of a project\n",
        "# if target_commit!=None: Extract all satds in a sequence of commits (preferably in the master branch) of a project that leads to a target commit\n",
        "def get_project_SATDs(files_hunks, target_commit=None):\n",
        "    num_files = len(files_hunks)\n",
        "    print('number of files in project:',num_files)\n",
        "\n",
        "    filecs_satds = {}\n",
        "    start_time = time.time()\n",
        "    \n",
        "    i = 0\n",
        "    for filec, sortedActions in files_hunks.items():  # filec is file or file_commit\n",
        "        i += 1\n",
        "        file = filec.split('_#_')[0]\n",
        "        if i%500==0:\n",
        "            #print('number of processed files: %d  file(_commit)=%s file_name=%s                         \\r'%(i,filec, files_name[file_id]), end=\"\")\n",
        "            print('number of processed files: %d  file(_commit)=%s                         '%(i,filec))\n",
        "        if file.endswith('.java'):  # ???? only java ????\n",
        "            filecs_satds[filec] = get_raw_SATDs(files_hunks[filec], 0) \n",
        "\n",
        "    print(\"--- It took %s seconds to extract all satds for this project                            \" % (time.time() - start_time))\n",
        "    return filecs_satds\n",
        "\n",
        "def SATDs_to_dataframe(filecs_satds):\n",
        "    lastAppearedInFile = []\n",
        "    fileDeleteInCommit = []\n",
        "    createdInFile = []\n",
        "    createdInLine = []\n",
        "    line = []\n",
        "    createdInCommit = []\n",
        "    deletedInCommit = []\n",
        "    createdInDate = []\n",
        "    deletedInDate = []\n",
        "    createdInHunk = []\n",
        "    deletedInHunk = []\n",
        "    content = []\n",
        "    prevLineContent = []\n",
        "    nextLineContent = []\n",
        "    for filec,satds in filecs_satds.items():\n",
        "        for satd in satds:\n",
        "            lastAppearedInFile.append(filec.split('_#_')[0])  # TODO: change _#_ to FILE_COMMIT_SEP\n",
        "            fileDeleteInCommit.append(filec.split('_#_')[1] if '_#_' in filec else None)\n",
        "            createdInFile.append(satd['created_in_file'])\n",
        "            createdInLine.append(satd['created_in_line'])\n",
        "            line.append(satd['line'])\n",
        "            createdInCommit.append(satd['created_in_commit'].hexsha)\n",
        "            deletedInCommit.append('' if satd['deleted_in_commit'] is None else satd['deleted_in_commit'].hexsha)\n",
        "            createdInDate.append(satd['created_in_commit'].committed_datetime)\n",
        "            deletedInDate.append('' if satd['deleted_in_commit'] is None else satd['deleted_in_commit'].committed_datetime)\n",
        "            createdInHunk.append(satd['created_in_hunk'])\n",
        "            deletedInHunk.append('' if satd['deleted_in_hunk'] is None else satd['deleted_in_hunk'])\n",
        "            content.append(satd['content'])\n",
        "            prevLineContent.append(satd['prev_line_content'])\n",
        "            nextLineContent.append(satd['next_line_content'])\n",
        "    df = pd.DataFrame(\n",
        "    {'createdInFile': createdInFile,\n",
        "     'lastAppearedInFile': lastAppearedInFile,\n",
        "     'lastFileDeleteInCommit': fileDeleteInCommit,\n",
        "     'createdInLine': createdInLine,\n",
        "     'lastAppearedInLine': line,\n",
        "     'createdInCommit': createdInCommit,\n",
        "     'deletedInCommit': deletedInCommit,\n",
        "     'createdInDate': createdInDate,\n",
        "     'deletedInDate': deletedInDate,\n",
        "     'createdInHunk': createdInHunk,\n",
        "     'deletedInHunk': deletedInHunk,\n",
        "     'content': content,\n",
        "     'prevLineContent': prevLineContent,\n",
        "     'nextLineContent': nextLineContent\n",
        "    })\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "tpoW_Rv6AtTr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fed1c79b-237b-422a-c95f-a450451bba43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'SATDs': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#%rm -r 'SATDs'\n",
        "!mkdir 'SATDs'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "I9PrZ7USOruV"
      },
      "outputs": [],
      "source": [
        "if None in files_hunks:\n",
        "    del files_hunks[None]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJcqM4b0AyWU",
        "outputId": "99b5eff1-6731-4182-de22-68f2a1aabf4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of files in project: 4771\n",
            "number of processed files: 500  file(_commit)=src/main/java/org/apache/commons/math/linear/BlockRealMatrix.java                         \n",
            "number of processed files: 1000  file(_commit)=src/main/java/org/apache/commons/math/ode/jacobians/FirstOrderIntegratorWithJacobians.java                         \n",
            "number of processed files: 1500  file(_commit)=src/test/java/org/apache/commons/math/optimization/univariate/UnivariateMultiStartOptimizerTest.java                         \n",
            "number of processed files: 2000  file(_commit)=src/main/java/org/apache/commons/math4/geometry/partitioning/Characterization.java                         \n",
            "number of processed files: 2500  file(_commit)=src/main/java/org/apache/commons/math4/transform/FastHadamardTransformer.java                         \n",
            "number of processed files: 3000  file(_commit)=src/test/java/org/apache/commons/math4/special/BesselJTest.java                         \n",
            "number of processed files: 3500  file(_commit)=commons-math-legacy/NOTICE                         \n",
            "number of processed files: 4000  file(_commit)=commons-math-legacy/src/main/java/org/apache/commons/math4/legacy/random/GaussianRandomGenerator.java                         \n",
            "number of processed files: 4500  file(_commit)=commons-math-legacy/src/test/java/org/apache/commons/math4/legacy/util/TestBean.java                         \n",
            "--- It took 10.721012592315674 seconds to extract all satds for this project                            \n"
          ]
        }
      ],
      "source": [
        "# Extract and track SATDs from files_hunks\n",
        "files_satds = get_project_SATDs(files_hunks)\n",
        "df = SATDs_to_dataframe(files_satds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "ab1z__6C0Qk_",
        "outputId": "b959e797-d569-4c08-c41c-502ddb2acf31"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         createdInFile  \\\n",
              "0    src/test/org/apache/commons/math/UnivariateImp...   \n",
              "1     src/java/org/apache/commons/math/Univariate.java   \n",
              "2     src/java/org/apache/commons/math/Univariate.java   \n",
              "3     src/java/org/apache/commons/math/Univariate.java   \n",
              "4    src/java/org/apache/commons/math/UnivariateImp...   \n",
              "..                                                 ...   \n",
              "668  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "669  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "670  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "671  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "672  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "\n",
              "                                    lastAppearedInFile lastFileDeleteInCommit  \\\n",
              "0    src/test/org/apache/commons/math/UnivariateImp...                   None   \n",
              "1    src/java/org/apache/commons/math/stat/Univaria...                   None   \n",
              "2    src/java/org/apache/commons/math/stat/Univaria...                   None   \n",
              "3    src/java/org/apache/commons/math/stat/Univaria...                   None   \n",
              "4    src/java/org/apache/commons/math/stat/Univaria...                   None   \n",
              "..                                                 ...                    ...   \n",
              "668  commons-math-legacy/src/test/java/org/apache/c...                   None   \n",
              "669  commons-math-legacy/src/test/java/org/apache/c...                   None   \n",
              "670  commons-math-legacy/src/test/java/org/apache/c...                   None   \n",
              "671  commons-math-legacy-core/src/test/java/org/apa...                   None   \n",
              "672  commons-math-legacy/src/test/java/org/apache/c...                   None   \n",
              "\n",
              "     createdInLine  lastAppearedInLine  \\\n",
              "0              200                 235   \n",
              "1              141                 141   \n",
              "2              151                 151   \n",
              "3              160                 160   \n",
              "4              104                 125   \n",
              "..             ...                 ...   \n",
              "668            250                 250   \n",
              "669            209                 211   \n",
              "670            527                 525   \n",
              "671            316                 316   \n",
              "672            318                 318   \n",
              "\n",
              "                              createdInCommit  \\\n",
              "0    b84e61ffcf873ef8d588ca3adce2bcd3c7406905   \n",
              "1    e4694325bc52209c0700294437d4e260991e9f82   \n",
              "2    e4694325bc52209c0700294437d4e260991e9f82   \n",
              "3    e4694325bc52209c0700294437d4e260991e9f82   \n",
              "4    97568dc06f50372c16e333e4c8367f845758470a   \n",
              "..                                        ...   \n",
              "668  9d1741bfe4a7808cfa0c313891a717adf98a3087   \n",
              "669  9d1741bfe4a7808cfa0c313891a717adf98a3087   \n",
              "670  9d1741bfe4a7808cfa0c313891a717adf98a3087   \n",
              "671  9d1741bfe4a7808cfa0c313891a717adf98a3087   \n",
              "672  e85e8b53f22d6b470492862a67f39068117bd175   \n",
              "\n",
              "                              deletedInCommit              createdInDate  \\\n",
              "0    429a652114f94bf81e97a7737f1b3ea63fb3de91  2003-05-23 17:33:18+00:00   \n",
              "1    97568dc06f50372c16e333e4c8367f845758470a  2003-05-12 19:04:38+00:00   \n",
              "2    97568dc06f50372c16e333e4c8367f845758470a  2003-05-12 19:04:38+00:00   \n",
              "3    97568dc06f50372c16e333e4c8367f845758470a  2003-05-12 19:04:38+00:00   \n",
              "4    b84e61ffcf873ef8d588ca3adce2bcd3c7406905  2003-05-15 05:39:01+00:00   \n",
              "..                                        ...                        ...   \n",
              "668                                            2021-05-15 05:36:48+02:00   \n",
              "669                                            2021-05-15 05:36:48+02:00   \n",
              "670                                            2021-05-15 05:36:48+02:00   \n",
              "671  c3ec07380f82c868dd015cf83f3ee2575c6fcd51  2021-05-15 05:36:48+02:00   \n",
              "672  c3ec07380f82c868dd015cf83f3ee2575c6fcd51  2021-06-01 00:26:35+02:00   \n",
              "\n",
              "                 deletedInDate  createdInHunk deletedInHunk  \\\n",
              "0    2003-05-29 23:25:12+00:00              3             0   \n",
              "1    2003-05-15 05:39:01+00:00              0             0   \n",
              "2    2003-05-15 05:39:01+00:00              0             0   \n",
              "3    2003-05-15 05:39:01+00:00              0             0   \n",
              "4    2003-05-23 17:33:18+00:00              0             2   \n",
              "..                         ...            ...           ...   \n",
              "668                                         0                 \n",
              "669                                         0                 \n",
              "670                                         0                 \n",
              "671  2021-06-01 01:25:15+02:00              0             0   \n",
              "672  2021-06-01 01:25:15+02:00              0             0   \n",
              "\n",
              "                                               content  \\\n",
              "0           //FiXME: test all other NaN contract specs   \n",
              "1        // FIXME: throw something meaningful if n = 0   \n",
              "2        // FIXME: throw something meaningful if n = 0   \n",
              "3        // FIXME: throw something meaningful if n = 0   \n",
              "4        // FIXME: throw something meaningful if n = 0   \n",
              "..                                                 ...   \n",
              "668  // From Wikipedia KS article - TODO: get (and ...   \n",
              "669  // TODO:  Should have assertRelativelyEquals(d...   \n",
              "670  //FIXME: get a real example to test against wi...   \n",
              "671  //  TODO: add this test in 4.0, as it is not p...   \n",
              "672  //  TODO: add this test in 4.0, as it is not p...   \n",
              "\n",
              "                                       prevLineContent  \\\n",
              "0                                                        \n",
              "1                            public double getMean() {   \n",
              "2                             double xbar = getMean();   \n",
              "3               public double getStandardDeviation() {   \n",
              "4                            public double getMean() {   \n",
              "..                                                 ...   \n",
              "668                                                 };   \n",
              "669  double[] glsBeta = glsModel.calculateBeta().to...   \n",
              "670                                                      \n",
              "671                                                      \n",
              "672                                                      \n",
              "\n",
              "                                       nextLineContent  \n",
              "0                                                    }  \n",
              "1                                        return sum/n;  \n",
              "2                  return (sumsq - xbar*xbar*n)/(n-1);  \n",
              "3                         return (new Double(Math.sqrt  \n",
              "4                          return (sum / (double) n );  \n",
              "..                                                 ...  \n",
              "668                               final double[] c = {  \n",
              "669  //        Should also add RealVector and RealM...  \n",
              "670           Assert.assertTrue(\"tighter means wider\",  \n",
              "671  //  due to incompatibility of the return type ...  \n",
              "672  //  due to incompatibility of the return type ...  \n",
              "\n",
              "[673 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16e68458-7d07-40c9-85a8-b7fd9d6d0bef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>createdInFile</th>\n",
              "      <th>lastAppearedInFile</th>\n",
              "      <th>lastFileDeleteInCommit</th>\n",
              "      <th>createdInLine</th>\n",
              "      <th>lastAppearedInLine</th>\n",
              "      <th>createdInCommit</th>\n",
              "      <th>deletedInCommit</th>\n",
              "      <th>createdInDate</th>\n",
              "      <th>deletedInDate</th>\n",
              "      <th>createdInHunk</th>\n",
              "      <th>deletedInHunk</th>\n",
              "      <th>content</th>\n",
              "      <th>prevLineContent</th>\n",
              "      <th>nextLineContent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>src/test/org/apache/commons/math/UnivariateImp...</td>\n",
              "      <td>src/test/org/apache/commons/math/UnivariateImp...</td>\n",
              "      <td>None</td>\n",
              "      <td>200</td>\n",
              "      <td>235</td>\n",
              "      <td>b84e61ffcf873ef8d588ca3adce2bcd3c7406905</td>\n",
              "      <td>429a652114f94bf81e97a7737f1b3ea63fb3de91</td>\n",
              "      <td>2003-05-23 17:33:18+00:00</td>\n",
              "      <td>2003-05-29 23:25:12+00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>//FiXME: test all other NaN contract specs</td>\n",
              "      <td></td>\n",
              "      <td>}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>src/java/org/apache/commons/math/Univariate.java</td>\n",
              "      <td>src/java/org/apache/commons/math/stat/Univaria...</td>\n",
              "      <td>None</td>\n",
              "      <td>141</td>\n",
              "      <td>141</td>\n",
              "      <td>e4694325bc52209c0700294437d4e260991e9f82</td>\n",
              "      <td>97568dc06f50372c16e333e4c8367f845758470a</td>\n",
              "      <td>2003-05-12 19:04:38+00:00</td>\n",
              "      <td>2003-05-15 05:39:01+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>// FIXME: throw something meaningful if n = 0</td>\n",
              "      <td>public double getMean() {</td>\n",
              "      <td>return sum/n;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>src/java/org/apache/commons/math/Univariate.java</td>\n",
              "      <td>src/java/org/apache/commons/math/stat/Univaria...</td>\n",
              "      <td>None</td>\n",
              "      <td>151</td>\n",
              "      <td>151</td>\n",
              "      <td>e4694325bc52209c0700294437d4e260991e9f82</td>\n",
              "      <td>97568dc06f50372c16e333e4c8367f845758470a</td>\n",
              "      <td>2003-05-12 19:04:38+00:00</td>\n",
              "      <td>2003-05-15 05:39:01+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>// FIXME: throw something meaningful if n = 0</td>\n",
              "      <td>double xbar = getMean();</td>\n",
              "      <td>return (sumsq - xbar*xbar*n)/(n-1);</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>src/java/org/apache/commons/math/Univariate.java</td>\n",
              "      <td>src/java/org/apache/commons/math/stat/Univaria...</td>\n",
              "      <td>None</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>e4694325bc52209c0700294437d4e260991e9f82</td>\n",
              "      <td>97568dc06f50372c16e333e4c8367f845758470a</td>\n",
              "      <td>2003-05-12 19:04:38+00:00</td>\n",
              "      <td>2003-05-15 05:39:01+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>// FIXME: throw something meaningful if n = 0</td>\n",
              "      <td>public double getStandardDeviation() {</td>\n",
              "      <td>return (new Double(Math.sqrt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>src/java/org/apache/commons/math/UnivariateImp...</td>\n",
              "      <td>src/java/org/apache/commons/math/stat/Univaria...</td>\n",
              "      <td>None</td>\n",
              "      <td>104</td>\n",
              "      <td>125</td>\n",
              "      <td>97568dc06f50372c16e333e4c8367f845758470a</td>\n",
              "      <td>b84e61ffcf873ef8d588ca3adce2bcd3c7406905</td>\n",
              "      <td>2003-05-15 05:39:01+00:00</td>\n",
              "      <td>2003-05-23 17:33:18+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>// FIXME: throw something meaningful if n = 0</td>\n",
              "      <td>public double getMean() {</td>\n",
              "      <td>return (sum / (double) n );</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>668</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>None</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>9d1741bfe4a7808cfa0c313891a717adf98a3087</td>\n",
              "      <td></td>\n",
              "      <td>2021-05-15 05:36:48+02:00</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>// From Wikipedia KS article - TODO: get (and ...</td>\n",
              "      <td>};</td>\n",
              "      <td>final double[] c = {</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>669</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>None</td>\n",
              "      <td>209</td>\n",
              "      <td>211</td>\n",
              "      <td>9d1741bfe4a7808cfa0c313891a717adf98a3087</td>\n",
              "      <td></td>\n",
              "      <td>2021-05-15 05:36:48+02:00</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>// TODO:  Should have assertRelativelyEquals(d...</td>\n",
              "      <td>double[] glsBeta = glsModel.calculateBeta().to...</td>\n",
              "      <td>//        Should also add RealVector and RealM...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>670</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>None</td>\n",
              "      <td>527</td>\n",
              "      <td>525</td>\n",
              "      <td>9d1741bfe4a7808cfa0c313891a717adf98a3087</td>\n",
              "      <td></td>\n",
              "      <td>2021-05-15 05:36:48+02:00</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>//FIXME: get a real example to test against wi...</td>\n",
              "      <td></td>\n",
              "      <td>Assert.assertTrue(\"tighter means wider\",</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy-core/src/test/java/org/apa...</td>\n",
              "      <td>None</td>\n",
              "      <td>316</td>\n",
              "      <td>316</td>\n",
              "      <td>9d1741bfe4a7808cfa0c313891a717adf98a3087</td>\n",
              "      <td>c3ec07380f82c868dd015cf83f3ee2575c6fcd51</td>\n",
              "      <td>2021-05-15 05:36:48+02:00</td>\n",
              "      <td>2021-06-01 01:25:15+02:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>//  TODO: add this test in 4.0, as it is not p...</td>\n",
              "      <td></td>\n",
              "      <td>//  due to incompatibility of the return type ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>672</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>None</td>\n",
              "      <td>318</td>\n",
              "      <td>318</td>\n",
              "      <td>e85e8b53f22d6b470492862a67f39068117bd175</td>\n",
              "      <td>c3ec07380f82c868dd015cf83f3ee2575c6fcd51</td>\n",
              "      <td>2021-06-01 00:26:35+02:00</td>\n",
              "      <td>2021-06-01 01:25:15+02:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>//  TODO: add this test in 4.0, as it is not p...</td>\n",
              "      <td></td>\n",
              "      <td>//  due to incompatibility of the return type ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>673 rows Ã— 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16e68458-7d07-40c9-85a8-b7fd9d6d0bef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16e68458-7d07-40c9-85a8-b7fd9d6d0bef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16e68458-7d07-40c9-85a8-b7fd9d6d0bef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Convert false positive SATD deletion/creation actions to SATD update actions"
      ],
      "metadata": {
        "id": "jPLRk52EVhVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "def add_followingSatdCandidates(df):\n",
        "    lastAppearedInFile = df['lastAppearedInFile']\n",
        "    createdInCommit = df['createdInCommit']\n",
        "    deletedInCommit = df['deletedInCommit']\n",
        "    followingSatdCandidates = len(lastAppearedInFile) * ['']\n",
        "    for i in range(len(lastAppearedInFile)):\n",
        "        for j in range(len(lastAppearedInFile)):\n",
        "            if i!=j and lastAppearedInFile[i]==lastAppearedInFile[j] and deletedInCommit[i]==createdInCommit[j]:\n",
        "                if followingSatdCandidates[i]=='':\n",
        "                    followingSatdCandidates[i] = str(j)\n",
        "                else:\n",
        "                    followingSatdCandidates[i] += ', '+str(j)\n",
        "    df['followingSatdCandidates'] = followingSatdCandidates\n",
        "    return df\n",
        "\n",
        "cachedStopWords = set(stopwords.words(\"english\")) # we cache it for better performance (this way it runs much faster!)\n",
        "def my_tokenizer(text, remove_singleCharWords=False, remove_stopwords=False, stemming=False):\n",
        "    #tokens = text.split(' ')\n",
        "    tokens = re.findall(r\"@\\w+|\\w+|\\S\", text)\n",
        "    #tokens = re.findall(r\"[A-Za-z]+|[0-9]+|\\S\", text)\n",
        "    #tokens = [word for word in nltk.word_tokenize(text)]\n",
        "    \n",
        "    if remove_singleCharWords:\n",
        "        tokens = [word for word in tokens if len(word)>1]\n",
        "    if remove_stopwords:\n",
        "        tokens = [word for word in tokens if not word.lower() in cachedStopWords and len(word)>1]\n",
        "    if stemming:\n",
        "        tokens = [stemmer.stem(item) for item in tokens]\n",
        "    return tokens\n",
        "\n",
        "# get two text and return the jaccard similarity\n",
        "def get_jaccard_sim(text1, text2, remove_singleCharWords, remove_stopwords):\n",
        "    if type(text1)==str:\n",
        "        text1_words = set(my_tokenizer(text1, remove_singleCharWords=remove_singleCharWords, remove_stopwords=remove_stopwords))\n",
        "    elif type(text1)==dict:\n",
        "        text1_words = set(text1.keys())\n",
        "    if type(text2)==str:\n",
        "        text2_words = set(my_tokenizer(text2, remove_singleCharWords=remove_singleCharWords, remove_stopwords=remove_stopwords))\n",
        "    elif type(text2)==dict:\n",
        "        text2_words = set(text2.keys())\n",
        "    if remove_stopwords:\n",
        "        text1_words = text1_words.difference(cachedStopWords)  # remove stopwords\n",
        "        text2_words = text2_words.difference(cachedStopWords)  # remove stopwords\n",
        "    intersec_words = text1_words.intersection(text2_words)\n",
        "    if len(text1_words)==0 and len(text2_words)==0:\n",
        "        return 0\n",
        "    return float(len(intersec_words)) / (len(text1_words) + len(text2_words) - len(intersec_words))\n",
        "\n",
        "def get_jaccard_sim_matrix(strList1, strList2, remove_singleCharWords, remove_stopwords):\n",
        "    matrix = np.zeros((len(strList1), len(strList2)))\n",
        "    for i in range(len(strList1)):\n",
        "        for j in range(len(strList2)):\n",
        "            matrix[i,j] = get_jaccard_sim(strList1[i], strList2[j], remove_singleCharWords, remove_stopwords)\n",
        "    return matrix\n",
        "\n",
        "def get_hunk_sim_matrix(hunkList1, hunkList2):\n",
        "    matrix = np.zeros((len(hunkList1), len(hunkList2)))\n",
        "    for i in range(len(hunkList1)):\n",
        "        for j in range(len(hunkList2)):\n",
        "            matrix[i,j] = 1 if hunkList1[i]==hunkList2[j] else 0\n",
        "    return matrix\n",
        "\n",
        "# for a specific file and a specific commit, it gets the iformation (e.g. prevLine, nextLine, str, hunk#) of deleted and inserted SATDs as List1 and List2 respectively\n",
        "# it returns an array of n by 2 that n is the number of found matches. For each match, it stores the index of deleted SATD in list1 and the index of new SATD in list2.\n",
        "def string_match(file_commit_id, strList1, strList2, prevList1, prevList2, nextList1, nextList2, hunkList1, hunkList2, strWeight, prevWeight, nextWeight, hunkWeight, threshold, remove_singleCharWords, remove_stopwords):\n",
        "    if not hasattr(string_match, \"cache\"):\n",
        "        string_match.cache = {}\n",
        "    if file_commit_id in string_match.cache:\n",
        "        matrixStr = string_match.cache[file_commit_id]['matrixStr']\n",
        "        matrixPrev = string_match.cache[file_commit_id]['matrixPrev']\n",
        "        matrixNext = string_match.cache[file_commit_id]['matrixNext']\n",
        "        matrixHunk = string_match.cache[file_commit_id]['matrixHunk']\n",
        "    else:\n",
        "        matrixStr = get_jaccard_sim_matrix(strList1, strList2, remove_singleCharWords, remove_stopwords)\n",
        "        matrixPrev = get_jaccard_sim_matrix(prevList1, prevList2, remove_singleCharWords, remove_stopwords)\n",
        "        matrixNext = get_jaccard_sim_matrix(nextList1, nextList2, remove_singleCharWords, remove_stopwords)\n",
        "        matrixHunk = get_hunk_sim_matrix(hunkList1, hunkList2)\n",
        "        string_match.cache[file_commit_id] = {}\n",
        "        string_match.cache[file_commit_id]['matrixStr'] = matrixStr\n",
        "        string_match.cache[file_commit_id]['matrixPrev'] = matrixPrev\n",
        "        string_match.cache[file_commit_id]['matrixNext'] = matrixNext\n",
        "        string_match.cache[file_commit_id]['matrixHunk'] = matrixHunk\n",
        "\n",
        "    matrix = strWeight*matrixStr + prevWeight*matrixPrev + nextWeight*matrixNext + hunkWeight*matrixHunk\n",
        "    matches=[]\n",
        "    while np.amax(matrix)>threshold:\n",
        "        maxInd = np.unravel_index(np.argmax(matrix, axis=None), matrix.shape)\n",
        "        matches.append(maxInd)\n",
        "        matrix[maxInd[0],:] = 0\n",
        "        matrix[:,maxInd[1]] = 0\n",
        "    return matches\n",
        "\n",
        "# returns a dictionary of files - commits - matchingSatds\n",
        "# matchingSatds contains the information of deleted and inserted Satds (like the Satd line, and its prevous and next lines) in that file-commit\n",
        "def get_files_commits_matchingSatds(df):\n",
        "    files_commits_matchingSatds = {}\n",
        "    for index, row in df.iterrows():\n",
        "        if len(row['followingSatdCandidates'])>0:\n",
        "            if row['lastAppearedInFile'] not in files_commits_matchingSatds:\n",
        "                files_commits_matchingSatds[row['lastAppearedInFile']] = {}\n",
        "            for candid in row['followingSatdCandidates'].split(','):\n",
        "                if row['deletedInCommit'] not in files_commits_matchingSatds[row['lastAppearedInFile']]:\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']] = {'indList1':[], 'indList2':[], 'strList1':[], 'strList2':[], 'prevList1':[], 'prevList2':[], 'nextList1':[], 'nextList2':[], 'hunkList1':[], 'hunkList2':[]}\n",
        "                candid = int(candid.strip())\n",
        "                if index not in files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['indList1']:\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['indList1'].append(index)\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['strList1'].append(row['content'])\n",
        "                    #files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['strList1'].append(re.split(';\\s*/*', row['content'])[-1]) # takes only the SATD part\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['prevList1'].append(row['prevLineContent'])\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['nextList1'].append(row['nextLineContent'])\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['hunkList1'].append(row['deletedInHunk'])\n",
        "                if candid not in files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['indList2']:\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['indList2'].append(candid)\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['strList2'].append(df.iloc[candid, df.columns.get_loc('content')])\n",
        "                    #files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['strList2'].append(re.split(';\\s*/*',df.iloc[candid, df.columns.get_loc('content')])[-1]) # takes only the SATD part\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['prevList2'].append(df.iloc[candid, df.columns.get_loc('prevLineContent')])\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['nextList2'].append(df.iloc[candid, df.columns.get_loc('nextLineContent')])\n",
        "                    files_commits_matchingSatds[row['lastAppearedInFile']][row['deletedInCommit']]['hunkList2'].append(df.iloc[candid, df.columns.get_loc('createdInHunk')])\n",
        "    return files_commits_matchingSatds \n",
        " \n",
        "def add_followingSatdByGreedy(df, files_commits_matchingSatds, strWeight, prevWeight, nextWeight, hunkWeight, threshold):\n",
        "    df['followingSatdByGreedy'] = ''\n",
        "    for file, commits_matchingSatds in files_commits_matchingSatds.items():\n",
        "        for commit, matchingSatds in commits_matchingSatds.items():\n",
        "            file_commit_id = file+'_'+commit\n",
        "            matches = string_match(file_commit_id, matchingSatds['strList1'], matchingSatds['strList2'], matchingSatds['prevList1'], matchingSatds['prevList2'], matchingSatds['nextList1'], matchingSatds['nextList2'], matchingSatds['hunkList1'], matchingSatds['hunkList2'], strWeight, prevWeight, nextWeight, hunkWeight, threshold, False, False)\n",
        "            for ind in matchingSatds['indList1']:\n",
        "                df.iloc[ind, df.columns.get_loc('followingSatdByGreedy')] = '-'\n",
        "            for match in matches:\n",
        "                df.iloc[matchingSatds['indList1'][match[0]], df.columns.get_loc('followingSatdByGreedy')] = matchingSatds['indList2'][match[1]]\n",
        "    return df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAfDG1BaVjRC",
        "outputId": "bd86e88e-5d95-4fa6-e8dd-65376481ac58"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'followingSatd' in df.columns:\n",
        "    df.followingSatd = df.followingSatd.fillna('')\n",
        "if 'prevLineContent' in df.columns:\n",
        "    df.prevLineContent = df.prevLineContent.fillna('')\n",
        "if 'nextLineContent' in df.columns:\n",
        "    df.nextLineContent = df.nextLineContent.fillna('')"
      ],
      "metadata": {
        "id": "yAiF3aAhVsvG"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = add_followingSatdCandidates(df)\n",
        "files_commits_matchingSatds = get_files_commits_matchingSatds(df)\n",
        "df = add_followingSatdByGreedy(df, files_commits_matchingSatds, 0.6, 0.2, 0, 0.2, 0.4) # these are the optimum weights we obtained through a grid search on a labeled dataset"
      ],
      "metadata": {
        "id": "IwJYpa9fVvYh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After finding the following SATDs, we can merge them and delete false positive rows.\n",
        "# When we merge them, we need to update some columns like deletedInCommit, line, and content\n",
        "def merge_followingSATDs_in_dataframe(df, followingSatdColumn, deleteFollowingSATDs):\n",
        "    df['followedBy'] = '' # the list of following SATDs. For example, if 11 follwos 10, and 12 follwos 11, this field will be \"11,12\" for row 10\n",
        "    df['deletedInLines'] = '' # it has the list of middle deleted lines. i.e. the lines when the SATD were updated.\n",
        "    df['createdInLines'] = '' # it has the list of middle created lines. i.e. the lines when the SATD were updated.\n",
        "    df['updatedInCommits'] = '' # it has the list of middle commits. \n",
        "    deleteIndices = []\n",
        "    for index, row in df.iterrows():\n",
        "        deletedInLines=[]\n",
        "        createdInLines=[]\n",
        "        content=row['content']\n",
        "        updatedInCommits = []\n",
        "        findex = index\n",
        "        while df.iloc[findex, df.columns.get_loc(followingSatdColumn)] not in ['','-']:\n",
        "            deletedInLines.append(df.iloc[findex, df.columns.get_loc('lastAppearedInLine')])\n",
        "            findex = df.iloc[findex, df.columns.get_loc(followingSatdColumn)]\n",
        "            df.iloc[index, df.columns.get_loc('followedBy')] += str(findex) + ','\n",
        "            createdInLines.append(df.iloc[findex, df.columns.get_loc('createdInLine')])\n",
        "            content += '\\n' + df.iloc[findex, df.columns.get_loc('content')]\n",
        "            updatedInCommits.append(df.iloc[findex, df.columns.get_loc('createdInCommit')])\n",
        "            deleteIndices.append(findex)\n",
        "        if findex!=index:\n",
        "            df.iloc[index, df.columns.get_loc('deletedInCommit')] = df.iloc[findex, df.columns.get_loc('deletedInCommit')]\n",
        "            df.iloc[index, df.columns.get_loc('deletedInHunk')] = df.iloc[findex, df.columns.get_loc('deletedInHunk')]\n",
        "            df.iloc[index, df.columns.get_loc('deletedInDate')] = df.iloc[findex, df.columns.get_loc('deletedInDate')]\n",
        "            df.iloc[index, df.columns.get_loc('lastAppearedInLine')] = df.iloc[findex, df.columns.get_loc('lastAppearedInLine')]\n",
        "            df.iloc[index, df.columns.get_loc('deletedInLines')] = str(deletedInLines)\n",
        "            df.iloc[index, df.columns.get_loc('createdInLines')] = str(createdInLines)\n",
        "            df.iloc[index, df.columns.get_loc('content')] = content\n",
        "            df.iloc[index, df.columns.get_loc('updatedInCommits')] = str(updatedInCommits)\n",
        "            if 'deletedInMaster' in df.columns:\n",
        "                df.iloc[index, df.columns.get_loc('deletedInMaster')] = df.iloc[findex, df.columns.get_loc('deletedInMaster')]\n",
        "\n",
        "    if deleteFollowingSATDs:\n",
        "        df = df.drop(index=deleteIndices)\n",
        "        df = df.reset_index(drop=True)\n",
        "        df = df.drop(columns=['followingSatdCandidates', 'followingSatdByGreedy', 'followingSatdCandidatesByFileRename', 'followingSatdByFileRename', 'followingSatdByHeuristics', 'followedBy'], errors='ignore')\n",
        "    df = df.drop(columns=['prevLineContent', 'nextLineContent'])\n",
        "    return df"
      ],
      "metadata": {
        "id": "d8xTq1g7VyOS"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge the following SATDs\n",
        "df2 = df.copy()\n",
        "df2 = merge_followingSATDs_in_dataframe(df2, 'followingSatdByGreedy', True)\n",
        "print(\"Number of deleted SATDs after merging them:\",len(df)-len(df2))\n",
        "print(\"Final number of SATDs:\",len(df2))\n",
        "df2.to_csv('SATD-merged.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSyrJBOsV0pe",
        "outputId": "502b7f2d-67e7-4fe0-b9e7-2e6b6f2a330f"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of deleted SATDs after merging them: 62\n",
            "Final number of SATDs: 611\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "dGv9X_YWhoX1",
        "outputId": "4588deaf-826e-489e-d02f-6eca27a3b1bd"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                         createdInFile  \\\n",
              "0    src/test/org/apache/commons/math/UnivariateImp...   \n",
              "1     src/java/org/apache/commons/math/Univariate.java   \n",
              "2     src/java/org/apache/commons/math/Univariate.java   \n",
              "3     src/java/org/apache/commons/math/Univariate.java   \n",
              "4    src/java/org/apache/commons/math/UnivariateImp...   \n",
              "..                                                 ...   \n",
              "606  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "607  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "608  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "609  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "610  commons-math-legacy/src/test/java/org/apache/c...   \n",
              "\n",
              "                                    lastAppearedInFile lastFileDeleteInCommit  \\\n",
              "0    src/test/org/apache/commons/math/UnivariateImp...                   None   \n",
              "1    src/java/org/apache/commons/math/stat/Univaria...                   None   \n",
              "2    src/java/org/apache/commons/math/stat/Univaria...                   None   \n",
              "3    src/java/org/apache/commons/math/stat/Univaria...                   None   \n",
              "4    src/java/org/apache/commons/math/stat/Univaria...                   None   \n",
              "..                                                 ...                    ...   \n",
              "606  commons-math-legacy/src/test/java/org/apache/c...                   None   \n",
              "607  commons-math-legacy/src/test/java/org/apache/c...                   None   \n",
              "608  commons-math-legacy/src/test/java/org/apache/c...                   None   \n",
              "609  commons-math-legacy-core/src/test/java/org/apa...                   None   \n",
              "610  commons-math-legacy/src/test/java/org/apache/c...                   None   \n",
              "\n",
              "     createdInLine  lastAppearedInLine  \\\n",
              "0              200                 235   \n",
              "1              141                 141   \n",
              "2              151                 151   \n",
              "3              160                 160   \n",
              "4              104                 125   \n",
              "..             ...                 ...   \n",
              "606            250                 250   \n",
              "607            209                 211   \n",
              "608            527                 525   \n",
              "609            316                 316   \n",
              "610            318                 318   \n",
              "\n",
              "                              createdInCommit  \\\n",
              "0    b84e61ffcf873ef8d588ca3adce2bcd3c7406905   \n",
              "1    e4694325bc52209c0700294437d4e260991e9f82   \n",
              "2    e4694325bc52209c0700294437d4e260991e9f82   \n",
              "3    e4694325bc52209c0700294437d4e260991e9f82   \n",
              "4    97568dc06f50372c16e333e4c8367f845758470a   \n",
              "..                                        ...   \n",
              "606  9d1741bfe4a7808cfa0c313891a717adf98a3087   \n",
              "607  9d1741bfe4a7808cfa0c313891a717adf98a3087   \n",
              "608  9d1741bfe4a7808cfa0c313891a717adf98a3087   \n",
              "609  9d1741bfe4a7808cfa0c313891a717adf98a3087   \n",
              "610  e85e8b53f22d6b470492862a67f39068117bd175   \n",
              "\n",
              "                              deletedInCommit              createdInDate  \\\n",
              "0    429a652114f94bf81e97a7737f1b3ea63fb3de91  2003-05-23 17:33:18+00:00   \n",
              "1    97568dc06f50372c16e333e4c8367f845758470a  2003-05-12 19:04:38+00:00   \n",
              "2    97568dc06f50372c16e333e4c8367f845758470a  2003-05-12 19:04:38+00:00   \n",
              "3    97568dc06f50372c16e333e4c8367f845758470a  2003-05-12 19:04:38+00:00   \n",
              "4    b84e61ffcf873ef8d588ca3adce2bcd3c7406905  2003-05-15 05:39:01+00:00   \n",
              "..                                        ...                        ...   \n",
              "606                                            2021-05-15 05:36:48+02:00   \n",
              "607                                            2021-05-15 05:36:48+02:00   \n",
              "608                                            2021-05-15 05:36:48+02:00   \n",
              "609  c3ec07380f82c868dd015cf83f3ee2575c6fcd51  2021-05-15 05:36:48+02:00   \n",
              "610  c3ec07380f82c868dd015cf83f3ee2575c6fcd51  2021-06-01 00:26:35+02:00   \n",
              "\n",
              "                 deletedInDate  createdInHunk deletedInHunk  \\\n",
              "0    2003-05-29 23:25:12+00:00              3             0   \n",
              "1    2003-05-15 05:39:01+00:00              0             0   \n",
              "2    2003-05-15 05:39:01+00:00              0             0   \n",
              "3    2003-05-15 05:39:01+00:00              0             0   \n",
              "4    2003-05-23 17:33:18+00:00              0             2   \n",
              "..                         ...            ...           ...   \n",
              "606                                         0                 \n",
              "607                                         0                 \n",
              "608                                         0                 \n",
              "609  2021-06-01 01:25:15+02:00              0             0   \n",
              "610  2021-06-01 01:25:15+02:00              0             0   \n",
              "\n",
              "                                               content deletedInLines  \\\n",
              "0           //FiXME: test all other NaN contract specs                  \n",
              "1        // FIXME: throw something meaningful if n = 0                  \n",
              "2        // FIXME: throw something meaningful if n = 0                  \n",
              "3        // FIXME: throw something meaningful if n = 0                  \n",
              "4        // FIXME: throw something meaningful if n = 0                  \n",
              "..                                                 ...            ...   \n",
              "606  // From Wikipedia KS article - TODO: get (and ...                  \n",
              "607  // TODO:  Should have assertRelativelyEquals(d...                  \n",
              "608  //FIXME: get a real example to test against wi...                  \n",
              "609  //  TODO: add this test in 4.0, as it is not p...                  \n",
              "610  //  TODO: add this test in 4.0, as it is not p...                  \n",
              "\n",
              "    createdInLines updatedInCommits  \n",
              "0                                    \n",
              "1                                    \n",
              "2                                    \n",
              "3                                    \n",
              "4                                    \n",
              "..             ...              ...  \n",
              "606                                  \n",
              "607                                  \n",
              "608                                  \n",
              "609                                  \n",
              "610                                  \n",
              "\n",
              "[611 rows x 15 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2f9cb00c-897d-4b70-af1f-3c7ee8c25f13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>createdInFile</th>\n",
              "      <th>lastAppearedInFile</th>\n",
              "      <th>lastFileDeleteInCommit</th>\n",
              "      <th>createdInLine</th>\n",
              "      <th>lastAppearedInLine</th>\n",
              "      <th>createdInCommit</th>\n",
              "      <th>deletedInCommit</th>\n",
              "      <th>createdInDate</th>\n",
              "      <th>deletedInDate</th>\n",
              "      <th>createdInHunk</th>\n",
              "      <th>deletedInHunk</th>\n",
              "      <th>content</th>\n",
              "      <th>deletedInLines</th>\n",
              "      <th>createdInLines</th>\n",
              "      <th>updatedInCommits</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>src/test/org/apache/commons/math/UnivariateImp...</td>\n",
              "      <td>src/test/org/apache/commons/math/UnivariateImp...</td>\n",
              "      <td>None</td>\n",
              "      <td>200</td>\n",
              "      <td>235</td>\n",
              "      <td>b84e61ffcf873ef8d588ca3adce2bcd3c7406905</td>\n",
              "      <td>429a652114f94bf81e97a7737f1b3ea63fb3de91</td>\n",
              "      <td>2003-05-23 17:33:18+00:00</td>\n",
              "      <td>2003-05-29 23:25:12+00:00</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>//FiXME: test all other NaN contract specs</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>src/java/org/apache/commons/math/Univariate.java</td>\n",
              "      <td>src/java/org/apache/commons/math/stat/Univaria...</td>\n",
              "      <td>None</td>\n",
              "      <td>141</td>\n",
              "      <td>141</td>\n",
              "      <td>e4694325bc52209c0700294437d4e260991e9f82</td>\n",
              "      <td>97568dc06f50372c16e333e4c8367f845758470a</td>\n",
              "      <td>2003-05-12 19:04:38+00:00</td>\n",
              "      <td>2003-05-15 05:39:01+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>// FIXME: throw something meaningful if n = 0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>src/java/org/apache/commons/math/Univariate.java</td>\n",
              "      <td>src/java/org/apache/commons/math/stat/Univaria...</td>\n",
              "      <td>None</td>\n",
              "      <td>151</td>\n",
              "      <td>151</td>\n",
              "      <td>e4694325bc52209c0700294437d4e260991e9f82</td>\n",
              "      <td>97568dc06f50372c16e333e4c8367f845758470a</td>\n",
              "      <td>2003-05-12 19:04:38+00:00</td>\n",
              "      <td>2003-05-15 05:39:01+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>// FIXME: throw something meaningful if n = 0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>src/java/org/apache/commons/math/Univariate.java</td>\n",
              "      <td>src/java/org/apache/commons/math/stat/Univaria...</td>\n",
              "      <td>None</td>\n",
              "      <td>160</td>\n",
              "      <td>160</td>\n",
              "      <td>e4694325bc52209c0700294437d4e260991e9f82</td>\n",
              "      <td>97568dc06f50372c16e333e4c8367f845758470a</td>\n",
              "      <td>2003-05-12 19:04:38+00:00</td>\n",
              "      <td>2003-05-15 05:39:01+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>// FIXME: throw something meaningful if n = 0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>src/java/org/apache/commons/math/UnivariateImp...</td>\n",
              "      <td>src/java/org/apache/commons/math/stat/Univaria...</td>\n",
              "      <td>None</td>\n",
              "      <td>104</td>\n",
              "      <td>125</td>\n",
              "      <td>97568dc06f50372c16e333e4c8367f845758470a</td>\n",
              "      <td>b84e61ffcf873ef8d588ca3adce2bcd3c7406905</td>\n",
              "      <td>2003-05-15 05:39:01+00:00</td>\n",
              "      <td>2003-05-23 17:33:18+00:00</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>// FIXME: throw something meaningful if n = 0</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>606</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>None</td>\n",
              "      <td>250</td>\n",
              "      <td>250</td>\n",
              "      <td>9d1741bfe4a7808cfa0c313891a717adf98a3087</td>\n",
              "      <td></td>\n",
              "      <td>2021-05-15 05:36:48+02:00</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>// From Wikipedia KS article - TODO: get (and ...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>607</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>None</td>\n",
              "      <td>209</td>\n",
              "      <td>211</td>\n",
              "      <td>9d1741bfe4a7808cfa0c313891a717adf98a3087</td>\n",
              "      <td></td>\n",
              "      <td>2021-05-15 05:36:48+02:00</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>// TODO:  Should have assertRelativelyEquals(d...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>None</td>\n",
              "      <td>527</td>\n",
              "      <td>525</td>\n",
              "      <td>9d1741bfe4a7808cfa0c313891a717adf98a3087</td>\n",
              "      <td></td>\n",
              "      <td>2021-05-15 05:36:48+02:00</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td></td>\n",
              "      <td>//FIXME: get a real example to test against wi...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>609</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy-core/src/test/java/org/apa...</td>\n",
              "      <td>None</td>\n",
              "      <td>316</td>\n",
              "      <td>316</td>\n",
              "      <td>9d1741bfe4a7808cfa0c313891a717adf98a3087</td>\n",
              "      <td>c3ec07380f82c868dd015cf83f3ee2575c6fcd51</td>\n",
              "      <td>2021-05-15 05:36:48+02:00</td>\n",
              "      <td>2021-06-01 01:25:15+02:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>//  TODO: add this test in 4.0, as it is not p...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>610</th>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>commons-math-legacy/src/test/java/org/apache/c...</td>\n",
              "      <td>None</td>\n",
              "      <td>318</td>\n",
              "      <td>318</td>\n",
              "      <td>e85e8b53f22d6b470492862a67f39068117bd175</td>\n",
              "      <td>c3ec07380f82c868dd015cf83f3ee2575c6fcd51</td>\n",
              "      <td>2021-06-01 00:26:35+02:00</td>\n",
              "      <td>2021-06-01 01:25:15+02:00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>//  TODO: add this test in 4.0, as it is not p...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>611 rows Ã— 15 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2f9cb00c-897d-4b70-af1f-3c7ee8c25f13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2f9cb00c-897d-4b70-af1f-3c7ee8c25f13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2f9cb00c-897d-4b70-af1f-3c7ee8c25f13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}